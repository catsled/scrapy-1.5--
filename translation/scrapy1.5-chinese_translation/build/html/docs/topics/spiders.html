

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spiders &mdash; my_project 0.15 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="my_project 0.15 documentation" href="../../index.html"/>
        <link rel="next" title="选择器" href="selectors.html"/>
        <link rel="prev" title="命令行工具" href="command_line_tool.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> my_project
          

          
          </a>

          
            
            
              <div class="version">
                0.15
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First step</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/scrapy_glance.html">Scrapy初见</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/scrapy_install.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/scrapy_tutorial.html">Scrapy 教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Concept</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="command_line_tool.html">命令行工具</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-spider">scrapy.Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="#spider-arguments">Spider arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generic-spiders">Generic Spiders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#crawlspider">CrawlSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#crawling-rules">Crawling rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#crawlspider-example">CrawlSpider example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#xmlfeedspider">XMLFeedSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#xmlfeedspider-example">XMLFeedSpider example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#csvfeedspider">CSVFeedSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">CSVFeedSpider 例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sitemapspider">SitemapSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sitemapspider-examples">SitemapSpider examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">选择器</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapy_shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item_pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed_exports.html">feed导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="link_extractors.html">链接提取器</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">配置(Settings)</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">my_project</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Spiders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/docs/topics/spiders.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spiders">
<span id="docs-topics-spiders"></span><h1>Spiders<a class="headerlink" href="#spiders" title="Permalink to this headline">¶</a></h1>
<p>Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页
的内容中提取结构化数据(爬取item)。 换句话说，Spider就是您定义爬取的动作及分析某个网页(或
者是有些网页)的地方。</p>
<p>对spider来说，爬取循环做着下面的事:</p>
<ol class="arabic">
<li><p class="first">首先通过初始化 requests 抓取第一个 URL，并设置回调函数。 当该 requests 下载完毕并返回时，
将生成 response ，然后作为参数传给该回调函数。</p>
<p>初始的 requests 是通过调用 <a class="reference internal" href="#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> 方法(默认情况下)为
<a class="reference internal" href="#scrapy.spiders.Spider.start_urls" title="scrapy.spiders.Spider.start_urls"><code class="xref py py-attr docutils literal notranslate"><span class="pre">start_urls</span></code></a> 中的URL生成初始 <a class="reference internal" href="#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> 请求
并且设置 <a class="reference internal" href="#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-attr docutils literal notranslate"><span class="pre">parse</span></code></a> 方法作为请求的回调函数。</p>
</li>
<li><p class="first">在回调函数中，您将解析 Response（网页）并返回带有提取后的数据的 dict ，<code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code> 对象，<code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code> 对象
或这些对象的可迭代容器。这些请求还将包含回调（可能是相同的），然后由 Scrapy 下载，然后由指定
的回调处理它们的响应。</p>
</li>
<li><p class="first">在回调函数中，您通常使用 <span class="xref std std-ref">docs-topics-selectors</span> 来解析页面内容（但您也可以使用BeautifulSoup，lxml或您喜欢的任何解析器），
并使用解析的数据生成 Item。</p>
</li>
<li><p class="first">最后，由spider返回的 item 通常会持久化存储到数据库中（在某些 <span class="xref std std-ref">Item Pipeline</span> 中进行存储操作）或者
使用 <span class="xref std std-ref">topics-feed-exports</span> 写入到文件中。</p>
</li>
</ol>
<p>虽然这个循环（或多或少）适用于任何种类的 spider，Scrapy 实现了不同种类的默认 spider 用于不同的需求。
我们将在这里谈论这些类型。</p>
<span class="target" id="module-scrapy.spiders"></span><div class="section" id="scrapy-spider">
<span id="topics-spiders-ref"></span><h2>scrapy.Spider<a class="headerlink" href="#scrapy-spider" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="scrapy.spiders.Spider">
<em class="property">class </em><code class="descclassname">scrapy.spiders.</code><code class="descname">Spider</code><a class="headerlink" href="#scrapy.spiders.Spider" title="Permalink to this definition">¶</a></dt>
<dd><p>这是最简单的spider，其他的spider必须继承该类（包括 Scrapy 自带的一些爬虫，以及你自己写的爬虫）。它不提供
任何特殊功能。它只是提供了一个默认的 <a class="reference internal" href="#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> 方法实现，它读取并请求爬虫的 <a class="reference internal" href="#scrapy.spiders.Spider.start_urls" title="scrapy.spiders.Spider.start_urls"><code class="xref py py-attr docutils literal notranslate"><span class="pre">start_urls</span></code></a> 属性，并为
每个结果响应调用爬虫的 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 方法。</p>
<dl class="attribute">
<dt id="scrapy.spiders.Spider.name">
<code class="descname">name</code><a class="headerlink" href="#scrapy.spiders.Spider.name" title="Permalink to this definition">¶</a></dt>
<dd><p>定义spider名字的字符串(string)。name定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。
不过您可以生成多个相同的spider实例(instance)，这没有任何限制。 name是spider最重要的属性，而且是必须的。</p>
<p>如果spider抓取单个网站（single domain），一个常见的做法是以该网站(domain)(加或不加 <a class="reference external" href="https://en.wikipedia.org/wiki/Top-level_domain">TLD</a> )来命名spider。
例如，如果爬取``mywebsite.com`` ，该spider通常会被命名为 <code class="docutils literal notranslate"><span class="pre">mywebsite</span></code> 。</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">在Python 2中，<code class="docutils literal notranslate"><span class="pre">name</span></code> 必须是 ASCII 格式。</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.Spider.allowed_domains">
<code class="descname">allowed_domains</code><a class="headerlink" href="#scrapy.spiders.Spider.allowed_domains" title="Permalink to this definition">¶</a></dt>
<dd><p>可选项。包含了spider允许抓取的域名列表。当 <code class="xref py py-class docutils literal notranslate"><span class="pre">OffsiteMiddleware</span></code> 启用时，不在域名列表中的URL不会被请求。</p>
<p>比如您的目标网址是 <code class="docutils literal notranslate"><span class="pre">https://www.example.com/1.html</span></code> ，然后将 <code class="docutils literal notranslate"><span class="pre">'example.com'</span></code> 添加到列表中。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.Spider.start_urls">
<code class="descname">start_urls</code><a class="headerlink" href="#scrapy.spiders.Spider.start_urls" title="Permalink to this definition">¶</a></dt>
<dd><p>URL列表。当没有指定特定 URL 时，爬虫将从从该列表中开始抓取。因此，爬取的第一个页面将是这里列出的某个URL。
后续的 URL 将根据从起始 URL 中获得的数据连续生成。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.Spider.custom_settings">
<code class="descname">custom_settings</code><a class="headerlink" href="#scrapy.spiders.Spider.custom_settings" title="Permalink to this definition">¶</a></dt>
<dd><p>该设置是一个dict。运行spider时改设置会覆盖项目级的设置。因为设置在实例化（instantiation）之前更新，所以它必须定义为类属性。</p>
<p>有关内置可用设置的列表，请参阅：<span class="xref std std-ref">topics-settings-ref</span>。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.Spider.crawler">
<code class="descname">crawler</code><a class="headerlink" href="#scrapy.spiders.Spider.crawler" title="Permalink to this definition">¶</a></dt>
<dd><p>该属性在初始化类之后由 <a class="reference internal" href="item_pipeline.html#from_crawler" title="from_crawler"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_crawler()</span></code></a> 类方法设置，并链接到该spider实例绑定的 <code class="xref py py-class docutils literal notranslate"><span class="pre">Crawler</span></code> 对象上。</p>
<p>Crawlers 在项目中封装了很多组件，作为单一入口访问（例如扩展，中间件，信号管理器等）。有关详情，请参阅 <span class="xref std std-ref">topics-api-crawler</span>。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.Spider.settings">
<code class="descname">settings</code><a class="headerlink" href="#scrapy.spiders.Spider.settings" title="Permalink to this definition">¶</a></dt>
<dd><p>spider 运行时的配置。这是一个 <code class="xref py py-class docutils literal notranslate"><span class="pre">Settings</span></code> 实例，详细了解请参考 <span class="xref std std-ref">topics-settings</span> 。
<code class="xref py py-class docutils literal notranslate"><span class="pre">Settings</span></code> instance, see the
<span class="xref std std-ref">topics-settings</span> topic for a detailed introduction on this subject.</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.Spider.logger">
<code class="descname">logger</code><a class="headerlink" href="#scrapy.spiders.Spider.logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Python Logger 使用 Spider 的 <a class="reference internal" href="#scrapy.spiders.Spider.name" title="scrapy.spiders.Spider.name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">name</span></code></a> 创建。您可以通过它发送日志消息，如 <span class="xref std std-ref">topics-logging-from-spiders</span>。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.Spider.from_crawler">
<code class="descname">from_crawler</code><span class="sig-paren">(</span><em>crawler</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.Spider.from_crawler" title="Permalink to this definition">¶</a></dt>
<dd><p>这是 Scrapy 用来创建 spider 的类方法。</p>
<p>您可能不需要直接重写它，因为默认实现充当 <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> 方法的代理，用给定的参数`args`和命名参数`kwargs`来调用它。</p>
<p>尽管如此，此方法会在新实例中设置 <a class="reference internal" href="#scrapy.spiders.Spider.crawler" title="scrapy.spiders.Spider.crawler"><code class="xref py py-attr docutils literal notranslate"><span class="pre">crawler</span></code></a> 和 <a class="reference internal" href="#scrapy.spiders.Spider.settings" title="scrapy.spiders.Spider.settings"><code class="xref py py-attr docutils literal notranslate"><span class="pre">settings</span></code></a> 属性，以便稍后在spider代码中访问它们。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>crawler</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Crawler</span></code> 实例) – spider将绑定到crawler</li>
<li><strong>args</strong> (<em>list</em>) – 传递给 <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> 方法的参数</li>
<li><strong>kwargs</strong> (<em>dict</em>) – 传递给 <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> 方法的关键字参数</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.Spider.start_requests">
<code class="descname">start_requests</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.Spider.start_requests" title="Permalink to this definition">¶</a></dt>
<dd><p>此方法必须返回一个可迭代对象（iterable），该对象包含了 spider 用于爬取的第一个Request。
当 spider 启动时，Scrapy 会调用该方法。此方法仅被调用一次，因此将 <a class="reference internal" href="#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> 作为生成器实现是安全的。</p>
<p>默认实现为:attr:<cite>start_urls`中的每个url生成``Request(url, dont_filter=True)`</cite>。</p>
<p>如果您想要修改最初爬取某个域名的Request对象，您可以重写(override)该方法。
例如，如果您需要在启动时使用POST请求登录，您可以:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;myspider&#39;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">FormRequest</span><span class="p">(</span><span class="s2">&quot;http://www.example.com/login&quot;</span><span class="p">,</span>
                                   <span class="n">formdata</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="s1">&#39;john&#39;</span><span class="p">,</span> <span class="s1">&#39;pass&#39;</span><span class="p">:</span> <span class="s1">&#39;secret&#39;</span><span class="p">},</span>
                                   <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">logged_in</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">logged_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1"># here you would extract links to follow and return Requests for</span>
        <span class="c1"># each of them, with another callback</span>
        <span class="k">pass</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.Spider.parse">
<code class="descname">parse</code><span class="sig-paren">(</span><em>response</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.Spider.parse" title="Permalink to this definition">¶</a></dt>
<dd><p>当 requests 请求没有指定回调函数时，这是Scrapy用来处理下载后的response的默认方法。</p>
<p><code class="docutils literal notranslate"><span class="pre">parse</span></code> 方法负责处理 response 并返回所抓取的数据以及(或者)后续的URL。<a class="reference internal" href="#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">Spider</span></code></a> 对其他的
Request的回调函数也有相同的要求。</p>
<p>此方法以及任何其他Request的回调函数必须返回一个可迭代的 <code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code> 或 dict 或 <code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code> 对象。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>response</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Response</span></code>) – 将要解析的 response 对象</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.Spider.log">
<code class="descname">log</code><span class="sig-paren">(</span><em>message</em><span class="optional">[</span>, <em>level</em>, <em>component</em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.Spider.log" title="Permalink to this definition">¶</a></dt>
<dd><p>通过 Spider 的 <a class="reference internal" href="#scrapy.spiders.Spider.logger" title="scrapy.spiders.Spider.logger"><code class="xref py py-attr docutils literal notranslate"><span class="pre">logger</span></code></a> 发送日志消息，保留向后兼容性。有关详细信息，请参阅
<span class="xref std std-ref">topics-logging-from-spiders</span>.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.Spider.closed">
<code class="descname">closed</code><span class="sig-paren">(</span><em>reason</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.Spider.closed" title="Permalink to this definition">¶</a></dt>
<dd><p>当spider关闭时，该函数被调用。 该方法提供了一个替代调用signals.connect()来监听 <code class="xref std std-signal docutils literal notranslate"><span class="pre">spider_closed</span></code> 信号的快捷方式。</p>
</dd></dl>

</dd></dl>

<p>让我们看个例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;A response from </span><span class="si">%s</span><span class="s1"> just arrived!&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<p>在单个回调函数中返回多个Request以及Item的例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">h3</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//h3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="n">h3</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>除了 <a class="reference internal" href="#scrapy.spiders.Spider.start_urls" title="scrapy.spiders.Spider.start_urls"><code class="xref py py-attr docutils literal notranslate"><span class="pre">start_urls</span></code></a> ，你也可以直接使用 <a class="reference internal" href="#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> ; 您也可以使用 <span class="xref std std-ref">topics-items</span>
来给予数据更多的结构性(give data more structure):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="k">import</span> <span class="n">MyItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;example.com&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="s1">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="s1">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="s1">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">h3</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//h3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">MyItem</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">h3</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="spider-arguments">
<span id="spiderargs"></span><h2>Spider arguments<a class="headerlink" href="#spider-arguments" title="Permalink to this headline">¶</a></h2>
<p>Spider 可以接收参数来修改其行为。spider 参数的一些常见用法是定义起始URL或限制要爬取一部分网站，
但实际上它们可以配置 spider 的任何功能。</p>
<p>Spider参数使用 <code class="docutils literal notranslate"><span class="pre">-a</span></code> 选项通过 <a class="reference internal" href="command_line_tool.html#std:command-crawl"><code class="xref std std-command docutils literal notranslate"><span class="pre">crawl</span></code></a> 命令传递。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">myspider</span> <span class="o">-</span><span class="n">a</span> <span class="n">category</span><span class="o">=</span><span class="n">electronics</span>
</pre></div>
</div>
<p>Spiders 可以通过 <cite>__init__</cite> 方法访问参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;myspider&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySpider</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/categories/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">category</span><span class="p">]</span>
        <span class="c1"># ...</span>
</pre></div>
</div>
<p>默认的 <cite>__init__</cite> 方法将获得所有的 spider 参数，并将参数作为 spider 的属性。
上面的例子也可以写作如下:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;myspider&#39;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="s1">&#39;http://www.example.com/categories/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">category</span><span class="p">)</span>
</pre></div>
</div>
<p>请记住，spider的参数只能是字符串。spider自己不会做任何解析。
如果打算通过命令行设置 <cite>start_urls</cite> 属性,你必须使用类似`ast.literal_eval &lt;<a class="reference external" href="https://docs.python.org/library/ast.html#ast.literal_eval">https://docs.python.org/library/ast.html#ast.literal_eval</a>&gt;`_
或`json.loads &lt;<a class="reference external" href="https://docs.python.org/library/json.html#json.loads">https://docs.python.org/library/json.html#json.loads</a>&gt;`_ 的方式将它解析到列表中，然后将其设置为属性。
否则，你会迭代一个 start_urls 字符串（一个非常常见的python陷阱），导致每个字符被看作一个单独的url。</p>
<p>一个有用的例子是通过 <code class="xref py py-class docutils literal notranslate"><span class="pre">HttpAuthMiddleware</span></code> 设置 http auth 证书或
通过 <code class="xref py py-class docutils literal notranslate"><span class="pre">UserAgentMiddleware</span></code> 设置 user agent:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">myspider</span> <span class="o">-</span><span class="n">a</span> <span class="n">http_user</span><span class="o">=</span><span class="n">myuser</span> <span class="o">-</span><span class="n">a</span> <span class="n">http_pass</span><span class="o">=</span><span class="n">mypassword</span> <span class="o">-</span><span class="n">a</span> <span class="n">user_agent</span><span class="o">=</span><span class="n">mybot</span>
</pre></div>
</div>
<p>Spider 参数也可以通过 Scrapyd <code class="docutils literal notranslate"><span class="pre">schedule.json</span></code> API 传递。
查看 <a class="reference external" href="https://scrapyd.readthedocs.io/en/latest/">Scrapyd documentation</a>.</p>
</div>
<div class="section" id="generic-spiders">
<span id="builtin-spiders"></span><h2>Generic Spiders<a class="headerlink" href="#generic-spiders" title="Permalink to this headline">¶</a></h2>
<p>Scrapy 自带一些有用的通用爬虫，你可以将自己的spider作为它们的子类。他们的目的是为一些常见的抓取案例提供方便的功能，
例如根据某些规则跟踪网站上的所有链接，从 <a class="reference external" href="https://www.sitemaps.org/index.html">Sitemaps</a> 抓取或解析XML / CSV Feed。</p>
<p>对于在下面的爬虫中使用的示例，我们假设你有一个项目，在 <code class="docutils literal notranslate"><span class="pre">myproject.items</span></code> 模块中声明一个 <code class="docutils literal notranslate"><span class="pre">TestItem</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">TestItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="crawlspider">
<h3>CrawlSpider<a class="headerlink" href="#crawlspider" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spiders.CrawlSpider">
<em class="property">class </em><code class="descclassname">scrapy.spiders.</code><code class="descname">CrawlSpider</code><a class="headerlink" href="#scrapy.spiders.CrawlSpider" title="Permalink to this definition">¶</a></dt>
<dd><p>这是最常用的爬取常规网站的spider，它提供了一个方便的机制，通过定义一组 rules 来跟踪链接。
它可能不是完全适合您的特定网站或项目，但它有几种通用例子，因此您可以以此为起点，
根据需要重写更多的自定义功能，当然也可以实现自己的spider。</p>
<p>除了从 Spider 继承的属性外（你必须指定），这个类还支持一个新的属性:</p>
<dl class="attribute">
<dt id="scrapy.spiders.CrawlSpider.rules">
<code class="descname">rules</code><a class="headerlink" href="#scrapy.spiders.CrawlSpider.rules" title="Permalink to this definition">¶</a></dt>
<dd><p>它是一个(或多个) <a class="reference internal" href="#scrapy.spiders.Rule" title="scrapy.spiders.Rule"><code class="xref py py-class docutils literal notranslate"><span class="pre">Rule</span></code></a> 对象的 List 列表. 每个 <a class="reference internal" href="#scrapy.spiders.Rule" title="scrapy.spiders.Rule"><code class="xref py py-class docutils literal notranslate"><span class="pre">Rule</span></code></a> 定义了爬取网址的特定行为。
Rule 对象的描述如下。如果多个 rules 匹配相同的链接，则会根据它在属性中定义的顺序使用第一个规则。</p>
</dd></dl>

<p>该spider也提供了一个可重写的方法:</p>
<dl class="method">
<dt id="scrapy.spiders.CrawlSpider.parse_start_url">
<code class="descname">parse_start_url</code><span class="sig-paren">(</span><em>response</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.CrawlSpider.parse_start_url" title="Permalink to this definition">¶</a></dt>
<dd><p>这个方法是start_urls的响应。它允许解析初始响应，并且必须得返回一个 <code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code> 对象，
一个:class:<cite>~scrapy.http.Request</cite> 对象或者一个包含其中任何一个对象的迭代器。</p>
</dd></dl>

</dd></dl>

<div class="section" id="crawling-rules">
<h4>Crawling rules<a class="headerlink" href="#crawling-rules" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="scrapy.spiders.Rule">
<em class="property">class </em><code class="descclassname">scrapy.spiders.</code><code class="descname">Rule</code><span class="sig-paren">(</span><em>link_extractor</em>, <em>callback=None</em>, <em>cb_kwargs=None</em>, <em>follow=None</em>, <em>process_links=None</em>, <em>process_request=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.Rule" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">link_extractor</span></code> 是一个链接提取器 <span class="xref std std-ref">Link Extractor</span> 对象，定义了如何从爬取的页面提取链接。</p>
<p><code class="docutils literal notranslate"><span class="pre">callback</span></code> 是一个 callable 或 string (此时，该 spider 中同名的函数将会被调用)，link_extractor 从 Response 对象中提取的
每个链接都会调用该函数。该回调函数接收一个 response 对象作为它的第一个参数，并且必须返回一个包含 <code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code>
及（或）:class:<cite>~scrapy.http.Request</cite> 对象（或它们的任何子类）的列表。</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">当编写爬虫规则时，避免使用 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 作为回调，因为 <a class="reference internal" href="#scrapy.spiders.CrawlSpider" title="scrapy.spiders.CrawlSpider"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrawlSpider</span></code></a> 本身使用 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 方法来实现其逻辑。
因此，如果您重写 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 方法，crawl spider 将会运行失败。</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">cb_kwargs</span></code> 包含传递给回调函数的参数(keyword argument)的字典</p>
<p><code class="docutils literal notranslate"><span class="pre">follow</span></code> 是一个布尔(boolean)值，指定了根据该规则从response提取的链接是否需要跟进。 如果 <code class="docutils literal notranslate"><span class="pre">callback</span></code> 为None， <code class="docutils literal notranslate"><span class="pre">follow</span></code> 默认设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，
否则默认为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p>
<p><code class="docutils literal notranslate"><span class="pre">process_links</span></code> 是一个 callable 或 string（此时，该spider中同名的函数将会被调用），使用 <code class="docutils literal notranslate"><span class="pre">link_extractor</span></code> 从 Response 对象中
提取的每个链接列表调用它。主要用来过滤链接。</p>
<p><code class="docutils literal notranslate"><span class="pre">process_request</span></code> 是一个 callable 或 string（此时，该spider中同名的函数将会被调用），它将被此规则提取的每个 request 调用，并且必须
返回一个 request 或 None（过滤掉该request）。</p>
</dd></dl>

</div>
<div class="section" id="crawlspider-example">
<h4>CrawlSpider example<a class="headerlink" href="#crawlspider-example" title="Permalink to this headline">¶</a></h4>
<p>现在让我们来看看一个带有 rule 的 CrawlSpider 示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.linkextractors</span> <span class="k">import</span> <span class="n">LinkExtractor</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com&#39;</span><span class="p">]</span>

    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
        <span class="c1"># Extract links matching &#39;category.php&#39; (but not matching &#39;subsection.php&#39;)</span>
        <span class="c1"># and follow links from them (since no callback means follow=True by default).</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;category\.php&#39;</span><span class="p">,</span> <span class="p">),</span> <span class="n">deny</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;subsection\.php&#39;</span><span class="p">,</span> <span class="p">))),</span>

        <span class="c1"># Extract links matching &#39;item.php&#39; and parse them with the spider&#39;s method parse_item</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;item\.php&#39;</span><span class="p">,</span> <span class="p">)),</span> <span class="n">callback</span><span class="o">=</span><span class="s1">&#39;parse_item&#39;</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Hi, this is an item page! </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//td[@id=&quot;item_id&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;ID: (\d+)&#39;</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//td[@id=&quot;item_name&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//td[@id=&quot;item_description&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>该spider将从 example.com 的首页开始爬取，获取category以及item的链接，后者使用 <code class="docutils literal notranslate"><span class="pre">parse_item</span></code> 方法解析响应。在 parse_item 方法中，
每个 response 将会被XPath处理，从HTML解析成数据并填入 <code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code> 中。</p>
</div>
</div>
<div class="section" id="xmlfeedspider">
<h3>XMLFeedSpider<a class="headerlink" href="#xmlfeedspider" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spiders.XMLFeedSpider">
<em class="property">class </em><code class="descclassname">scrapy.spiders.</code><code class="descname">XMLFeedSpider</code><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider" title="Permalink to this definition">¶</a></dt>
<dd><p>XMLFeedSpider被设计用于通过迭代各个节点来分析XML源(XML feed)。迭代器可以从: <code class="docutils literal notranslate"><span class="pre">iternodes</span></code>, <code class="docutils literal notranslate"><span class="pre">xml</span></code>,
和 <code class="docutils literal notranslate"><span class="pre">html</span></code> 选择。出于性能的考虑，建议使用 iternodes 迭代器，因为``xml`` 和 <code class="docutils literal notranslate"><span class="pre">html``迭代器会一次生成整个DOM，然后在解析它。</span>
<span class="pre">但是，使用</span> <span class="pre">``html</span></code> 作为迭代器可以有效应对有错误标记的XML。</p>
<p>要设置 iterator 迭代器和 tag name 标签名称，您必须定义以下类属性:</p>
<dl class="attribute">
<dt id="scrapy.spiders.XMLFeedSpider.iterator">
<code class="descname">iterator</code><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p>定义要使用的迭代器的string。可选项有:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">'iternodes'</span></code> - 一个高性能的基于正则表达式的迭代器</li>
<li><code class="docutils literal notranslate"><span class="pre">'html'</span></code> - 使用 <code class="xref py py-class docutils literal notranslate"><span class="pre">Selector</span></code> 的迭代器。需要注意的是该迭代器使用DOM进行分析，
其需要将所有的DOM载入内存，当数据量很大的时候会产生问题</li>
<li><code class="docutils literal notranslate"><span class="pre">'xml'</span></code> - 使用 <code class="xref py py-class docutils literal notranslate"><span class="pre">Selector</span></code> 的迭代器。需要注意的是该迭代器使用DOM进行分析，
其需要将所有的DOM载入内存，当数据量很大的时候会产生问题</li>
</ul>
</div></blockquote>
<p>它的默认值: <code class="docutils literal notranslate"><span class="pre">'iternodes'</span></code>.</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.XMLFeedSpider.itertag">
<code class="descname">itertag</code><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider.itertag" title="Permalink to this definition">¶</a></dt>
<dd><p>一个包含开始迭代的节点名的string。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">itertag</span> <span class="o">=</span> <span class="s1">&#39;product&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.XMLFeedSpider.namespaces">
<code class="descname">namespaces</code><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider.namespaces" title="Permalink to this definition">¶</a></dt>
<dd><p>一个由 <code class="docutils literal notranslate"><span class="pre">(prefix,</span> <span class="pre">uri)</span></code> 元组(tuple)所组成的list。 其定义了在该文档中会被spider处理的可用的namespace。
<code class="docutils literal notranslate"><span class="pre">prefix</span></code> 及 <code class="docutils literal notranslate"><span class="pre">uri</span></code> 会被自动调用 <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_namespace()</span></code> 生成namespace。</p>
<p>您可以通过在 <a class="reference internal" href="#scrapy.spiders.XMLFeedSpider.itertag" title="scrapy.spiders.XMLFeedSpider.itertag"><code class="xref py py-attr docutils literal notranslate"><span class="pre">itertag</span></code></a> 属性中制定节点的namespace。</p>
<p>例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">YourSpider</span><span class="p">(</span><span class="n">XMLFeedSpider</span><span class="p">):</span>

    <span class="n">namespaces</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;http://www.sitemaps.org/schemas/sitemap/0.9&#39;</span><span class="p">)]</span>
    <span class="n">itertag</span> <span class="o">=</span> <span class="s1">&#39;n:url&#39;</span>
    <span class="c1"># ...</span>
</pre></div>
</div>
</dd></dl>

<p>除了这些新的属性之外，该spider也有以下可以覆盖(overrideable)的方法:</p>
<dl class="method">
<dt id="scrapy.spiders.XMLFeedSpider.adapt_response">
<code class="descname">adapt_response</code><span class="sig-paren">(</span><em>response</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider.adapt_response" title="Permalink to this definition">¶</a></dt>
<dd><p>该方法在spider的middleware(中间件)收到response时调用。您可以在 response 被解析之前使用该函数来修改响应的内容。
该方法接受一个response并返回一个response(可以相同也可以不同)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.XMLFeedSpider.parse_node">
<code class="descname">parse_node</code><span class="sig-paren">(</span><em>response</em>, <em>selector</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider.parse_node" title="Permalink to this definition">¶</a></dt>
<dd><p>当节点符合提供的标签名时(<code class="docutils literal notranslate"><span class="pre">itertag</span></code>)该方法被调用。该方法接收 response 以及相应的 <code class="xref py py-class docutils literal notranslate"><span class="pre">Selector</span></code> 作为参数。重写此方法是强制性的，
否则，你的spider将无法工作。该方法返回一个 <code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code> 对象或者 <code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code> 对象 或者一个包含二者的可迭代对象(iterable)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.XMLFeedSpider.process_results">
<code class="descname">process_results</code><span class="sig-paren">(</span><em>response</em>, <em>results</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.XMLFeedSpider.process_results" title="Permalink to this definition">¶</a></dt>
<dd><p>当spider返回结果(item或request)时该方法被调用。 设定该方法的目的是在结果返回给框架核心(framework core)之前做最后的处理， 例如设定item的ID。
其接受一个结果的列表(list of results)及对应的response。 其结果必须返回一个结果的列表(list of results)(包含Item或者Request对象)。</p>
</dd></dl>

</dd></dl>

<div class="section" id="xmlfeedspider-example">
<h4>XMLFeedSpider example<a class="headerlink" href="#xmlfeedspider-example" title="Permalink to this headline">¶</a></h4>
<p>很容易使用的spider。看个例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">XMLFeedSpider</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="k">import</span> <span class="n">TestItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">XMLFeedSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/feed.xml&#39;</span><span class="p">]</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="s1">&#39;iternodes&#39;</span>  <span class="c1"># This is actually unnecessary, since it&#39;s the default value</span>
    <span class="n">itertag</span> <span class="o">=</span> <span class="s1">&#39;item&#39;</span>

    <span class="k">def</span> <span class="nf">parse_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Hi, this is a &lt;</span><span class="si">%s</span><span class="s1">&gt; node!: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">itertag</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">extract</span><span class="p">()))</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">TestItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;@id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;description&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>简单来说，我们做的就是创建一个spider，从给定的``start_urls``下载一个 feed.xml 文件，然后遍历每个``item``标签，
打印出来，并将一些随机数据存储在一个 <code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code> 中。</p>
</div>
</div>
<div class="section" id="csvfeedspider">
<h3>CSVFeedSpider<a class="headerlink" href="#csvfeedspider" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spiders.CSVFeedSpider">
<em class="property">class </em><code class="descclassname">scrapy.spiders.</code><code class="descname">CSVFeedSpider</code><a class="headerlink" href="#scrapy.spiders.CSVFeedSpider" title="Permalink to this definition">¶</a></dt>
<dd><p>该spider和XMLFeedSpider十分类似, 不同在于这个spider是按行遍历而不是节点遍历。每次迭代调用的方法是 <a class="reference internal" href="#scrapy.spiders.CSVFeedSpider.parse_row" title="scrapy.spiders.CSVFeedSpider.parse_row"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse_row()</span></code></a>.</p>
<dl class="attribute">
<dt id="scrapy.spiders.CSVFeedSpider.delimiter">
<code class="descname">delimiter</code><a class="headerlink" href="#scrapy.spiders.CSVFeedSpider.delimiter" title="Permalink to this definition">¶</a></dt>
<dd><p>在CSV文件中用于区分字段的分隔符。类型为string。 默认为 <code class="docutils literal notranslate"><span class="pre">','</span></code> (逗号)。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.CSVFeedSpider.quotechar">
<code class="descname">quotechar</code><a class="headerlink" href="#scrapy.spiders.CSVFeedSpider.quotechar" title="Permalink to this definition">¶</a></dt>
<dd><p>在CSV文件中每个字段的外围字符的字符串默认是 <code class="docutils literal notranslate"><span class="pre">'&quot;'</span></code> (引号)。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.CSVFeedSpider.headers">
<code class="descname">headers</code><a class="headerlink" href="#scrapy.spiders.CSVFeedSpider.headers" title="Permalink to this definition">¶</a></dt>
<dd><p>CSV文件中列名称的列表。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spiders.CSVFeedSpider.parse_row">
<code class="descname">parse_row</code><span class="sig-paren">(</span><em>response</em>, <em>row</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spiders.CSVFeedSpider.parse_row" title="Permalink to this definition">¶</a></dt>
<dd><p>该方法接收一个response对象及一个以提供或检测出来的header为键的字典(代表每行)。 该spider中，您也可以
重写 <code class="docutils literal notranslate"><span class="pre">adapt_response</span></code> 及 <code class="docutils literal notranslate"><span class="pre">process_results</span></code> 方法来进行预处理(pre-processing)及后处理(post-processing)。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id1">
<h4>CSVFeedSpider 例子<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>下面的例子和之前的例子很像，但使用了
<a class="reference internal" href="#scrapy.spiders.CSVFeedSpider" title="scrapy.spiders.CSVFeedSpider"><code class="xref py py-class docutils literal notranslate"><span class="pre">CSVFeedSpider</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">CSVFeedSpider</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="k">import</span> <span class="n">TestItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CSVFeedSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/feed.csv&#39;</span><span class="p">]</span>
    <span class="n">delimiter</span> <span class="o">=</span> <span class="s1">&#39;;&#39;</span>
    <span class="n">quotechar</span> <span class="o">=</span> <span class="s2">&quot;&#39;&quot;</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;description&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Hi, this is a row!: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">TestItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="sitemapspider">
<h3>SitemapSpider<a class="headerlink" href="#sitemapspider" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spiders.SitemapSpider">
<em class="property">class </em><code class="descclassname">scrapy.spiders.</code><code class="descname">SitemapSpider</code><a class="headerlink" href="#scrapy.spiders.SitemapSpider" title="Permalink to this definition">¶</a></dt>
<dd><p>SitemapSpider使您爬取网站时可以通过 Sitemaps 来发现爬取的URL。其支持嵌套的sitemap，并能从robots.txt中获取 <a class="reference external" href="https://www.sitemaps.org/index.html">Sitemaps</a> 的url。</p>
<dl class="attribute">
<dt id="scrapy.spiders.SitemapSpider.sitemap_urls">
<code class="descname">sitemap_urls</code><a class="headerlink" href="#scrapy.spiders.SitemapSpider.sitemap_urls" title="Permalink to this definition">¶</a></dt>
<dd><p>包含您要爬取的url的sitemap的url列表(list)。
您也可以指定为一个 robots.txt ，spider会从中分析并提取url。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.SitemapSpider.sitemap_rules">
<code class="descname">sitemap_rules</code><a class="headerlink" href="#scrapy.spiders.SitemapSpider.sitemap_rules" title="Permalink to this definition">¶</a></dt>
<dd><p>一个包含 <code class="docutils literal notranslate"><span class="pre">(regex,</span> <span class="pre">callback)</span></code> 元组的 list 列表:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">regex</span></code> 是一个用于匹配从sitemap提取的url的正则表达式
<code class="docutils literal notranslate"><span class="pre">regex</span></code> 可以是一个字符串或者编译过的正则对象</li>
<li>callback指定了匹配正则表达式的url的处理函数。 <code class="docutils literal notranslate"><span class="pre">callback</span></code> 可以是一个字符串(spider中的方法名)或者是callable。</li>
</ul>
<p>例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;/product/&#39;</span><span class="p">,</span> <span class="s1">&#39;parse_product&#39;</span><span class="p">)]</span>
</pre></div>
</div>
<p>规则按顺序进行匹配，之后第一个匹配才会被应用。</p>
<p>如果您忽略该属性，sitemap中发现的所有url将会被 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 函数处理。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.SitemapSpider.sitemap_follow">
<code class="descname">sitemap_follow</code><a class="headerlink" href="#scrapy.spiders.SitemapSpider.sitemap_follow" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div>一个用于匹配要跟进的sitemap的正则表达式的列表(list)。这仅适用于使用 <a class="reference external" href="https://www.sitemaps.org/protocol.html#index">Sitemap index files</a> 来指向其他sitemap文件的站点。</div></blockquote>
<p>默认情况下，所有的sitemap都会被跟进。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spiders.SitemapSpider.sitemap_alternate_links">
<code class="descname">sitemap_alternate_links</code><a class="headerlink" href="#scrapy.spiders.SitemapSpider.sitemap_alternate_links" title="Permalink to this definition">¶</a></dt>
<dd><p>指定是否应该跟进一个url的可选链接。有些网站会在一个 url 块内提供其他语言的网站链接。</p>
<p>例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">url</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">loc</span><span class="o">&gt;</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">example</span><span class="o">.</span><span class="n">com</span><span class="o">/&lt;/</span><span class="n">loc</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">xhtml</span><span class="p">:</span><span class="n">link</span> <span class="n">rel</span><span class="o">=</span><span class="s2">&quot;alternate&quot;</span> <span class="n">hreflang</span><span class="o">=</span><span class="s2">&quot;de&quot;</span> <span class="n">href</span><span class="o">=</span><span class="s2">&quot;http://example.com/de&quot;</span><span class="o">/&gt;</span>
<span class="o">&lt;/</span><span class="n">url</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>当 <code class="docutils literal notranslate"><span class="pre">sitemap_alternate_links</span></code> 被启用时, 两个URL都会被获取。当``sitemap_alternate_links`` 关闭时, 只有 <code class="docutils literal notranslate"><span class="pre">http://example.com/</span></code> 会被获取</p>
<p><code class="docutils literal notranslate"><span class="pre">sitemap_alternate_links</span></code> 默认是关闭的。</p>
</dd></dl>

</dd></dl>

<div class="section" id="sitemapspider-examples">
<h4>SitemapSpider examples<a class="headerlink" href="#sitemapspider-examples" title="Permalink to this headline">¶</a></h4>
<p>简单的例子: 使用 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 回调函数处理通过sitemap发现的所有url:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c1"># ... scrape item here ...</span>
</pre></div>
</div>
<p>针对不同的 URL 使用不同的callback回调函数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;/product/&#39;</span><span class="p">,</span> <span class="s1">&#39;parse_product&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;/category/&#39;</span><span class="p">,</span> <span class="s1">&#39;parse_category&#39;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c1"># ... scrape product ...</span>

    <span class="k">def</span> <span class="nf">parse_category</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c1"># ... scrape category ...</span>
</pre></div>
</div>
<p>跟进 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> 文件定义的sitemap并只跟进包含有 <code class="docutils literal notranslate"><span class="pre">/sitemap_shop</span></code> 的url:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/robots.txt&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;/shop/&#39;</span><span class="p">,</span> <span class="s1">&#39;parse_shop&#39;</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="n">sitemap_follow</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;/sitemap_shops&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_shop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c1"># ... scrape shop here ...</span>
</pre></div>
</div>
<p>将SitemapSpider与其他URL来源相结合:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/robots.txt&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;/shop/&#39;</span><span class="p">,</span> <span class="s1">&#39;parse_shop&#39;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">other_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.example.com/about&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">super</span><span class="p">(</span><span class="n">MySpider</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">start_requests</span><span class="p">())</span>
        <span class="n">requests</span> <span class="o">+=</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_other</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_urls</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">requests</span>

    <span class="k">def</span> <span class="nf">parse_shop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c1"># ... scrape shop here ...</span>

    <span class="k">def</span> <span class="nf">parse_other</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c1"># ... scrape other here ...</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="selectors.html" class="btn btn-neutral float-right" title="选择器" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="command_line_tool.html" class="btn btn-neutral" title="命令行工具" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, mas.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.15',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>


</body>
</html>